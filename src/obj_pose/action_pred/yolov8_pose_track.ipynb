{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv8-Pose and Action Prediction:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Demo Video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10 sec video\n",
    "!gdown https://drive.google.com/uc?id=1t0EctgtEbiW5WEv6gZkTMw2TjQlDjkry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics==8.0.93\n",
    "!pip install gdown\n",
    "!pip install imageio[ffmpeg]\n",
    "!pip install imageio[pyav]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOLOv8-custom.pt model.\n",
    "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-pose.pt\n",
    "## YOLOv8x-pose-p6.pt model for pose estimation.\n",
    "!gdown https://drive.google.com/uc?id=1CJjmDetBADOd6DUIPgSgZUghqEGF3EcS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_angle(joint_a, joint_b, image_width, image_height):\n",
    "\n",
    "    norm_joint_a = [joint_a[0] / image_width, joint_a[1] / image_height, joint_a[2]]\n",
    "    norm_joint_b = [joint_b[0] / image_width, joint_b[1] / image_height, joint_b[2]]\n",
    "\n",
    "    vector = [norm_joint_b[0] - norm_joint_a[0], norm_joint_b[1] - norm_joint_a[1], norm_joint_b[2] - norm_joint_a[2]]\n",
    "    \n",
    "    magnitude = math.sqrt(vector[0] ** 2 + vector[1] ** 2 + vector[2] ** 2)\n",
    "    \n",
    "    angle_rad = math.acos(vector[2] / magnitude)\n",
    "    \n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "    \n",
    "    return angle_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(joint_a, joint_b, image_width, image_height):\n",
    "    norm_joint_a = [joint_a[0] / image_width, joint_a[1] / image_height, joint_a[2]]\n",
    "    norm_joint_b = [joint_b[0] / image_width, joint_b[1] / image_height, joint_b[2]]\n",
    "\n",
    "    distance = math.sqrt((norm_joint_b[0] - norm_joint_a[0])**2 + (norm_joint_b[1] - norm_joint_a[1])**2 + (norm_joint_b[2] - norm_joint_a[2])**2)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "model = YOLO('yolov8x_custom.pt')\n",
    "model_pose = YOLO('yolov8x-pose-p6.pt')\n",
    "\n",
    "video_path = \"quality.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "output_path = \"output.mp4\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        results_boxes = model.predict(frame, save=True, imgsz=1920, conf=0.5)\n",
    "        results_poses = model_pose.predict(frame, save=True, imgsz=1920, conf=0.001)\n",
    "\n",
    "        n = len(results_boxes[0])\n",
    "        i = 0\n",
    "        for keypoint in results_poses[0].keypoints:\n",
    "\n",
    "          joint_right_foot = keypoint[16].tolist()\n",
    "          joint_left_foot = keypoint[15].tolist()\n",
    "          joint_right_knee = keypoint[14].tolist()\n",
    "          joint_left_knee = keypoint[13].tolist()\n",
    "          joint_right_arm = keypoint[10].tolist()\n",
    "          joint_left_arm = keypoint[6].tolist()\n",
    "          joint_right_shoulder = keypoint[9].tolist()\n",
    "          joint_left_shoulder = keypoint[5].tolist()\n",
    "          joint_right_hip = keypoint[12].tolist()\n",
    "          joint_left_hip = keypoint[11].tolist()\n",
    "\n",
    "\n",
    "          angle_knee = calculate_angle(joint_right_knee, joint_left_knee, frame.shape[1], frame.shape[0])\n",
    "          angle_kick_right = calculate_angle(joint_right_foot, joint_right_hip, frame.shape[1], frame.shape[0])\n",
    "          angle_kick_left = calculate_angle(joint_left_foot, joint_left_hip, frame.shape[1], frame.shape[0])\n",
    "          angle_left_arm = calculate_angle(joint_left_shoulder, joint_left_arm, frame.shape[1], frame.shape[0])\n",
    "          angle_right_arm = calculate_angle(joint_right_shoulder, joint_left_shoulder, frame.shape[1], frame.shape[0])\n",
    "\n",
    "          distance_knee = calculate_distance(joint_left_knee, joint_right_knee, frame.shape[1], frame.shape[0])\n",
    "          distance_left_palm = calculate_distance(joint_left_arm, joint_left_shoulder, frame.shape[1], frame.shape[0])\n",
    "          distance_right_palm = calculate_distance(joint_right_arm, joint_right_shoulder, frame.shape[1], frame.shape[0])\n",
    "\n",
    "          \n",
    "          if distance_knee >= 0.01 and (abs(angle_left_arm) >= 20 or abs(angle_right_arm) >= 20):\n",
    "            print(f\"Player on x:{results_boxes[0].boxes[i].xyxy.cpu().tolist()[0][0]} y:{results_boxes[0].boxes[i].xyxy.cpu().tolist()[0][1]} is running: \")\n",
    "          elif abs(angle_kick_left) >= 80 or abs(angle_kick_right) >= 80:\n",
    "            print(f\"Player on x:{results_boxes[0].boxes[i].xyxy.cpu().tolist()[0][0]} y:{results_boxes[0].boxes[i].xyxy.cpu().tolist()[0][1]} is kicking: \")\n",
    "          else:\n",
    "            print(f\"Player on x:{results_boxes[0].boxes[i].xyxy.cpu().tolist()[0][0]} y:{results_boxes[0].boxes[i].xyxy.cpu().tolist()[0][1]} is standing or doing nothing: \")\n",
    "          i += 1\n",
    "          if i == n:\n",
    "            break\n",
    "        \n",
    "        annotated_frame_poses = results_poses[0].plot(boxes=False)\n",
    "        annotated_frame_boxes = results_boxes[0].plot()\n",
    "        merged_frame = cv2.addWeighted(annotated_frame_boxes, 0.5, annotated_frame_poses, 0.5, 0)\n",
    "\n",
    "        out.write(merged_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def display_video(video):\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "    mov = []\n",
    "    for i in range(len(video)): \n",
    "        img = plt.imshow(video[i], animated=True)\n",
    "        plt.axis('off')\n",
    "        mov.append([img])\n",
    "\n",
    "    anime = animation.ArtistAnimation(fig, mov, interval=50, repeat_delay=1000)\n",
    "\n",
    "    plt.close()\n",
    "    return anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = imageio.mimread(f'./runs/track/exp/quality.mp4', memtest=False)\n",
    "HTML(display_video(video).to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FI",
   "language": "python",
   "name": "fi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
